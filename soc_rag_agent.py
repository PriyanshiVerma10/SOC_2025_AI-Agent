# -*- coding: utf-8 -*-
"""soc_rag_agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lda-jGNImNJfa4swmV2X4pFHEWQi3zoV
"""

from google.colab import files
uploaded = files.upload()

!pip install dotenv

from dotenv import find_dotenv, load_dotenv
import os

load_dotenv(find_dotenv())
os.environ["GROQ_API_KEY"] = 'abcd'
groq_api_key = os.environ["GROQ_API_KEY"]

!pip install langchain-groq

from langchain_groq import ChatGroq
llama = ChatGroq(api_key=groq_api_key, model="llama-3.3-70b-versatile")

llama.invoke("Tell me about yourself")

llama.invoke("differences in llama and llama3?")

!pip install langchain-community

!pip install pypdf

from langchain_community.document_loaders import PyPDFLoader
pdf_loader = PyPDFLoader("SoS endterm.pdf")
pages = pdf_loader.load()

len(pages)

from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter  = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)

split_pages = text_splitter.split_documents(pages)

print(f"Total chunks: {len(split_pages)}")

!pip install chromadb sentence_transformers huggingface_hub langchain_chroma

import chromadb
from langchain_chroma import Chroma
from langchain_community.embeddings import HuggingFaceBgeEmbeddings

embeddings = HuggingFaceBgeEmbeddings(
    model_name="BAAI/bge-small-en-v1.5",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)

persist_directory = "./SoS_endterm"
collection_name = "SoS_endterm"

if not os.path.exists(persist_directory):
    os.makedirs(persist_directory)


try:
    vectorstore = Chroma.from_documents(
        documents=split_pages,
        embedding=embeddings,
        persist_directory=persist_directory,
        collection_name=collection_name
    )
    print(f"Created ChromaDB vector store!")

except Exception as e:
    print(f"Error setting up ChromaDB: {str(e)}")
    raise

from langchain_core.tools import tool, StructuredTool

retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 5}
)

@tool
def retriever_tool(query: str) -> str:
    """Search information from
    given document based on the query."""
    docs = retriever.invoke(query)

    if not docs:
        return "I found no relevant info in this document."

    results = []
    for i, doc in enumerate(docs):
        results.append(f"Document {i+1}:\n{doc.page_content}")

    return "\n\n".join(results)


tools = [retriever_tool]

llama = llama.bind_tools(tools)

llama_with_tools = llama.bind_tools(tools, tool_choice="auto")

ai_msg = llama_with_tools.invoke("Whats topic of document")

print(ai_msg.content)
print(ai_msg.tool_calls)

!pip install langgraph

from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
import operator
from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage

class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], operator.add]   ## {'messages': []}

class RAGAgent:

    def __init__(self, model, tools, system="You are a helpful assistant."):
        self.system = system
        self.tools = {t.name: t for t in tools}
        self.model = model.bind_tools(tools, tool_choice="auto")

        graph = StateGraph(AgentState)
        graph.add_node("llama", self.call_llm)
        graph.add_node("retriever", self.take_action)
        graph.add_conditional_edges(
            "llama",
            self.exists_action,
            {True: "retriever", False: END}
        )
        graph.add_edge("retriever", "llama")
        graph.set_entry_point("llama")
        self.graph = graph.compile()

    def exists_action(self, state: AgentState):
        result = state['messages'][-1]
        return len(result.tool_calls) > 0

    def call_llm(self, state: AgentState):
        messages = state['messages']
        if self.system:
            messages = [SystemMessage(content=self.system)] + messages
        message = self.model.invoke(messages)
        return {'messages': [message]}

    def take_action(self, state: AgentState):
        tool_calls = state['messages'][-1].tool_calls
        results = []
        for t in tool_calls:
            print(f"Calling Tool: {t}")
            if not t['name'] in self.tools:
                print(f"\n Tool: {t} does not exist.")
                result = "Incorrect Tool Name, Please Retry and Select tool from List of Available tools."
            else:
                result = self.tools[t['name']].invoke(t['args'])
            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))
        return {'messages': results}

prompt = """
You are teaching assistant. Use the retriever tool to answer questions.
You are allowed to make multiple calls.
"""

agent = RAGAgent(llama, tools, system=prompt)

messages = [HumanMessage(content="Hello, How are you?")]

result = agent.graph.invoke({"messages": messages})

result['messages'][-1].content

messages = [HumanMessage(content="What are futures?. Answer in short")]

result = agent.graph.invoke({"messages": messages})

result

result['messages'][-1].content

messages = [HumanMessage(content="Difference between futures and forwards")]

result = agent.graph.invoke({"messages": messages})

print(result['messages'][-1].content)

